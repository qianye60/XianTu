/**
 * ç»Ÿä¸€AIæœåŠ¡ - æ”¯æŒé…’é¦†å’Œè‡ªå®šä¹‰API
 *
 * åŒæ¨¡å¼æ¶æ„ï¼š
 * 1. é…’é¦†æ¨¡å¼ï¼ˆTavernï¼‰:
 *    - ä¸»APIï¼ˆmainï¼‰: æ°¸è¿œé€šè¿‡é…’é¦†TavernHelperè°ƒç”¨ï¼Œä½¿ç”¨é…’é¦†é…ç½®çš„API
 *    - è¾…åŠ©åŠŸèƒ½ï¼ˆcot/text_optimizationç­‰ï¼‰: å¦‚æœé…ç½®äº†ç‹¬ç«‹APIï¼Œåˆ™ä½¿ç”¨è‡ªå®šä¹‰APIè°ƒç”¨
 *
 * 2. ç½‘é¡µæ¨¡å¼ï¼ˆWeb/Customï¼‰:
 *    - æ‰€æœ‰åŠŸèƒ½éƒ½é€šè¿‡é…ç½®çš„è‡ªå®šä¹‰APIè°ƒç”¨
 *    - å¯ä¸ºä¸åŒåŠŸèƒ½åˆ†é…ä¸åŒçš„API
 */
import axios from 'axios';
import type { APIUsageType, APIConfig as StoreAPIConfig } from '@/stores/apiManagementStore';

// ============ APIæä¾›å•†ç±»å‹ ============
export type APIProvider = 'openai' | 'claude' | 'gemini' | 'deepseek' | 'custom';

// ============ é…ç½®æ¥å£ ============
export interface AIConfig {
  mode: 'tavern' | 'custom';
  streaming?: boolean;
  memorySummaryMode?: 'raw' | 'standard';
  initMode?: 'generate' | 'generateRaw';
  customAPI?: {
    provider: APIProvider;  // APIæä¾›å•†
    url: string;
    apiKey: string;
    model: string;
    temperature?: number;
    maxTokens?: number;
  };
}

// APIæä¾›å•†é¢„è®¾é…ç½®
export const API_PROVIDER_PRESETS: Record<APIProvider, { url: string; defaultModel: string; name: string }> = {
  openai: { url: 'https://api.openai.com', defaultModel: 'gpt-4o', name: 'OpenAI' },
  claude: { url: 'https://api.anthropic.com', defaultModel: 'claude-sonnet-4-20250514', name: 'Claude' },
  gemini: { url: 'https://generativelanguage.googleapis.com', defaultModel: 'gemini-2.0-flash', name: 'Gemini' },
  deepseek: { url: 'https://api.deepseek.com', defaultModel: 'deepseek-chat', name: 'DeepSeek' },
  custom: { url: '', defaultModel: '', name: 'è‡ªå®šä¹‰(OpenAIå…¼å®¹)' }
};

export interface AIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface GenerateOptions {
  user_input?: string;
  ordered_prompts?: AIMessage[];
  should_stream?: boolean;
  generation_id?: string;
  /** åŠŸèƒ½ç±»å‹ï¼Œç”¨äºå¤šAPIé…ç½®æ—¶é€‰æ‹©å¯¹åº”çš„APIï¼Œä¸å¡«åˆ™ä½¿ç”¨ä¸»API */
  usageType?: APIUsageType;
  injects?: Array<{
    content: string;
    role: 'system' | 'assistant' | 'user';
    depth: number;
    position: 'in_chat' | 'none';
  }>;
  overrides?: {
    world_info_before?: string;
    world_info_after?: string;
  };
  onStreamChunk?: (chunk: string) => void;
}

// ============ AIæœåŠ¡ç±» ============
class AIService {
  private config: AIConfig = {
    mode: 'tavern',
    streaming: true,
    memorySummaryMode: 'raw',
    initMode: 'generate',
    customAPI: {
      provider: 'openai',
      url: '',
      apiKey: '',
      model: 'gpt-4o',
      temperature: 0.7,
      maxTokens: 16000  // è¾“å‡ºtokenä¸Šé™
    }
  };

  // ç”¨äºå–æ¶ˆæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚
  private abortController: AbortController | null = null;
  private isAborted = false;

  constructor() {
    this.loadConfig();
  }

  /**
   * å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ï¼ˆåŒ…æ‹¬é‡è¯•ä¸­çš„è¯·æ±‚ï¼‰
   */
  cancelAllRequests() {
    console.log('[AIæœåŠ¡] å–æ¶ˆæ‰€æœ‰è¯·æ±‚');
    this.isAborted = true;
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
  }

  /**
   * é‡ç½®å–æ¶ˆçŠ¶æ€ï¼ˆåœ¨æ–°è¯·æ±‚å¼€å§‹å‰è°ƒç”¨ï¼‰
   */
  private resetAbortState() {
    this.isAborted = false;
    this.abortController = new AbortController();
  }

  private syncModeWithEnvironment() {
    this.config.mode = this.isTavernEnvironment() ? 'tavern' : 'custom';
  }

  private loadConfig() {
    try {
      const saved = localStorage.getItem('ai_service_config');
      if (saved) {
        const parsed = JSON.parse(saved);
        this.config = { ...this.config, ...parsed };
        console.log('[AIæœåŠ¡] é…ç½®å·²åŠ è½½:', this.config.mode);
        // å¼ºåˆ¶æŒ‰è¿è¡Œç¯å¢ƒé€‰æ‹©é»˜è®¤æ¨¡å¼ï¼šé…’é¦†=é…’é¦†APIï¼Œéé…’é¦†=è‡ªå®šä¹‰API
        this.syncModeWithEnvironment();
        return;
      }
      // æ²¡æœ‰ä¿å­˜é…ç½®æ—¶ï¼šé…’é¦†é»˜è®¤ç”¨é…’é¦†æ¨¡å¼ï¼Œç½‘é¡µç‰ˆé»˜è®¤ç”¨è‡ªå®šä¹‰API
      this.syncModeWithEnvironment();
    } catch (e) {
      console.error('[AIæœåŠ¡] åŠ è½½é…ç½®å¤±è´¥:', e);
    }
  }

  saveConfig(config: Partial<AIConfig>) {
    this.config = { ...this.config, ...config };
    // å¼ºåˆ¶æŒ‰è¿è¡Œç¯å¢ƒé€‰æ‹©é»˜è®¤æ¨¡å¼ï¼šé…’é¦†=é…’é¦†APIï¼Œéé…’é¦†=è‡ªå®šä¹‰API
    this.syncModeWithEnvironment();
    // è‡ªåŠ¨æ¸…ç†è‡ªå®šä¹‰API URLæœ«å°¾çš„ /v1 å’Œ / åç¼€
    if (this.config.customAPI?.url) {
      this.config.customAPI.url = this.config.customAPI.url
        .replace(/\/v1\/?$/, '')  // ç§»é™¤æœ«å°¾çš„ /v1 æˆ– /v1/
        .replace(/\/+$/, '');      // ç§»é™¤æœ«å°¾çš„æ–œæ 
    }
    localStorage.setItem('ai_service_config', JSON.stringify(this.config));
    console.log('[AIæœåŠ¡] é…ç½®å·²ä¿å­˜:', this.config.mode);
  }

  /**
   * ç›´æ¥ä½¿ç”¨æŒ‡å®šAPIé…ç½®è¿›è¡Œæµ‹è¯•ï¼ˆç»•è¿‡ç¯å¢ƒæ£€æµ‹ï¼Œå¼ºåˆ¶ç›´è¿ï¼‰
   */
  async testAPIDirectly(apiConfig: {
    provider: APIProvider;
    url: string;
    apiKey: string;
    model: string;
    temperature?: number;
    maxTokens?: number;
  }, testPrompt: string): Promise<string> {
    console.log(`[AIæœåŠ¡] ç›´æ¥æµ‹è¯•API: ${apiConfig.url}, model: ${apiConfig.model}`);

    // ä¸´æ—¶ä¿å­˜å½“å‰é…ç½®
    const originalConfig = this.config.customAPI ? { ...this.config.customAPI } : null;
    const originalMode = this.config.mode;

    try {
      // å¼ºåˆ¶ä½¿ç”¨customæ¨¡å¼å’ŒæŒ‡å®šçš„APIé…ç½®
      this.config.mode = 'custom';
      this.config.customAPI = {
        provider: apiConfig.provider,
        url: apiConfig.url.replace(/\/v1\/?$/, '').replace(/\/+$/, ''),
        apiKey: apiConfig.apiKey,
        model: apiConfig.model,
        temperature: apiConfig.temperature ?? 0.7,
        maxTokens: apiConfig.maxTokens ?? 1000
      };

      // ç›´æ¥è°ƒç”¨è‡ªå®šä¹‰APIï¼ˆä¸èµ°ç¯å¢ƒæ£€æµ‹ï¼‰
      return await this.generateWithCustomAPI({
        user_input: testPrompt,
        should_stream: false
      });
    } finally {
      // æ¢å¤åŸé…ç½®
      this.config.mode = originalMode;
      if (originalConfig) {
        this.config.customAPI = originalConfig;
      }
    }
  }

  getConfig(): AIConfig {
    return { ...this.config };
  }

  /**
   * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  async fetchModels(): Promise<string[]> {
    if (!this.config.customAPI?.url || !this.config.customAPI?.apiKey) {
      throw new Error('è¯·å…ˆé…ç½®APIåœ°å€å’Œå¯†é’¥');
    }

    try {
      const baseUrl = this.config.customAPI.url.replace(/\/+$/, '');
      const response = await axios.get(`${baseUrl}/v1/models`, {
        headers: { 'Authorization': `Bearer ${this.config.customAPI.apiKey}` }
      });

      return response.data.data?.map((m: any) => m.id) || [];
    } catch (error) {
      console.error('[AIæœåŠ¡] è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error);
      throw new Error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥');
    }
  }

  /**
   * æ ¹æ® usageType è·å–å¯¹åº”çš„ API é…ç½®
   * è¿”å› null è¡¨ç¤ºä½¿ç”¨é»˜è®¤é…ç½®
   */
  private getAPIConfigForUsageType(usageType?: APIUsageType): StoreAPIConfig | null {
    if (!usageType) return null;

    try {
      // åŠ¨æ€å¯¼å…¥ store é¿å…å¾ªç¯ä¾èµ–
      // eslint-disable-next-line @typescript-eslint/no-require-imports
      const { useAPIManagementStore } = require('@/stores/apiManagementStore');
      const apiStore = useAPIManagementStore();

      // è·å–è¯¥åŠŸèƒ½åˆ†é…çš„ API
      const apiConfig = apiStore.getAPIForType(usageType);
      if (!apiConfig) return null;

      // å¦‚æœæ˜¯é»˜è®¤ APIï¼Œè¿”å› null è¡¨ç¤ºä½¿ç”¨ä¸»é…ç½®
      if (apiConfig.id === 'default') return null;

      return apiConfig;
    } catch (e) {
      console.warn('[AIæœåŠ¡] è·å–åŠŸèƒ½APIé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®:', e);
      return null;
    }
  }

  /**
   * æ ‡å‡†ç”Ÿæˆï¼ˆå¸¦è§’è‰²å¡ã€èŠå¤©å†å²ï¼‰
   *
   * é…’é¦†ç«¯é€»è¾‘ï¼š
   * - usageType='main' æˆ–æœªæŒ‡å®š â†’ æ°¸è¿œèµ°é…’é¦†TavernHelper
   * - å…¶ä»–usageTypeä¸”é…ç½®äº†ç‹¬ç«‹API â†’ èµ°è‡ªå®šä¹‰API
   *
   * ç½‘é¡µç«¯é€»è¾‘ï¼š
   * - æ ¹æ®usageTypeæŸ¥æ‰¾å¯¹åº”APIé…ç½®
   * - å¦‚æœæ²¡æœ‰é…ç½®ç‹¬ç«‹APIï¼Œä½¿ç”¨é»˜è®¤API
   */
  async generate(options: GenerateOptions): Promise<string> {
    // é‡ç½®å–æ¶ˆçŠ¶æ€
    this.resetAbortState();

    this.syncModeWithEnvironment();
    const usageType = options.usageType || 'main';
    console.log(`[AIæœåŠ¡] è°ƒç”¨generateï¼Œæ¨¡å¼: ${this.config.mode}, usageType: ${usageType}`);

    // é…’é¦†æ¨¡å¼ç‰¹æ®Šå¤„ç†
    if (this.config.mode === 'tavern') {
      // æ£€æŸ¥æ˜¯å¦é…ç½®äº†ç‹¬ç«‹APIï¼ˆédefaultï¼‰
      const apiConfig = this.getAPIConfigForUsageType(usageType);

      // å¦‚æœé…ç½®äº†ç‹¬ç«‹APIï¼Œç›´æ¥è¯·æ±‚ï¼Œä¸èµ°é…’é¦†ä»£ç†
      if (apiConfig) {
        console.log(`[AIæœåŠ¡-é…’é¦†] åŠŸèƒ½[${usageType}]ä½¿ç”¨ç‹¬ç«‹APIç›´è¿: ${apiConfig.name}`);
        return this.generateWithAPIConfig(options, {
          provider: apiConfig.provider,
          url: apiConfig.url,
          apiKey: apiConfig.apiKey,
          model: apiConfig.model,
          temperature: apiConfig.temperature,
          maxTokens: apiConfig.maxTokens
        });
      }

      // æ²¡æœ‰é…ç½®ç‹¬ç«‹APIï¼ˆä½¿ç”¨defaultï¼‰ï¼Œèµ°é…’é¦†
      console.log(`[AIæœåŠ¡-é…’é¦†] åŠŸèƒ½[${usageType}]ä½¿ç”¨é…’é¦†TavernHelper`);
      return this.generateWithTavern(options);
    }

    // ç½‘é¡µæ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨ç‰¹å®šåŠŸèƒ½çš„ API é…ç½®
    const apiConfig = this.getAPIConfigForUsageType(usageType);
    if (apiConfig) {
      console.log(`[AIæœåŠ¡-ç½‘é¡µ] ä½¿ç”¨åŠŸèƒ½[${usageType}]åˆ†é…çš„API: ${apiConfig.name}`);
      return this.generateWithAPIConfig(options, {
        provider: apiConfig.provider,
        url: apiConfig.url,
        apiKey: apiConfig.apiKey,
        model: apiConfig.model,
        temperature: apiConfig.temperature,
        maxTokens: apiConfig.maxTokens
      });
    }

    // ç½‘é¡µæ¨¡å¼é»˜è®¤
    return this.generateWithCustomAPI(options);
  }

  /**
   * çº¯å‡€ç”Ÿæˆï¼ˆä¸å¸¦è§’è‰²å¡ï¼‰
   *
   * é…’é¦†ç«¯é€»è¾‘ï¼š
   * - usageType='main' æˆ–æœªæŒ‡å®š â†’ æ°¸è¿œèµ°é…’é¦†TavernHelper
   * - å…¶ä»–usageTypeä¸”é…ç½®äº†ç‹¬ç«‹API â†’ èµ°è‡ªå®šä¹‰API
   *
   * ç½‘é¡µç«¯é€»è¾‘ï¼š
   * - æ ¹æ®usageTypeæŸ¥æ‰¾å¯¹åº”APIé…ç½®
   * - å¦‚æœæ²¡æœ‰é…ç½®ç‹¬ç«‹APIï¼Œä½¿ç”¨é»˜è®¤API
   */
  async generateRaw(options: GenerateOptions): Promise<string> {
    this.syncModeWithEnvironment();
    const usageType = options.usageType || 'main';
    console.log(`[AIæœåŠ¡] è°ƒç”¨generateRawï¼Œæ¨¡å¼: ${this.config.mode}, usageType: ${usageType}`);

    // é…’é¦†æ¨¡å¼ç‰¹æ®Šå¤„ç†
    if (this.config.mode === 'tavern') {
      // æ£€æŸ¥æ˜¯å¦é…ç½®äº†ç‹¬ç«‹APIï¼ˆédefaultï¼‰
      const apiConfig = this.getAPIConfigForUsageType(usageType);

      // å¦‚æœé…ç½®äº†ç‹¬ç«‹APIï¼Œç›´æ¥è¯·æ±‚ï¼Œä¸èµ°é…’é¦†ä»£ç†
      if (apiConfig) {
        console.log(`[AIæœåŠ¡-é…’é¦†] åŠŸèƒ½[${usageType}]ä½¿ç”¨ç‹¬ç«‹APIç›´è¿(Raw): ${apiConfig.name}`);
        return this.generateRawWithAPIConfig(options, {
          provider: apiConfig.provider,
          url: apiConfig.url,
          apiKey: apiConfig.apiKey,
          model: apiConfig.model,
          temperature: apiConfig.temperature,
          maxTokens: apiConfig.maxTokens
        });
      }

      // æ²¡æœ‰é…ç½®ç‹¬ç«‹APIï¼ˆä½¿ç”¨defaultï¼‰ï¼Œèµ°é…’é¦†
      console.log(`[AIæœåŠ¡-é…’é¦†] åŠŸèƒ½[${usageType}]ä½¿ç”¨é…’é¦†TavernHelper(Raw)`);
      return this.generateRawWithTavern(options);
    }

    // ç½‘é¡µæ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨ç‰¹å®šåŠŸèƒ½çš„ API é…ç½®
    const apiConfig = this.getAPIConfigForUsageType(usageType);
    if (apiConfig) {
      console.log(`[AIæœåŠ¡-ç½‘é¡µ] ä½¿ç”¨åŠŸèƒ½[${usageType}]åˆ†é…çš„API: ${apiConfig.name}`);
      return this.generateRawWithAPIConfig(options, {
        provider: apiConfig.provider,
        url: apiConfig.url,
        apiKey: apiConfig.apiKey,
        model: apiConfig.model,
        temperature: apiConfig.temperature,
        maxTokens: apiConfig.maxTokens
      });
    }

    // ç½‘é¡µæ¨¡å¼é»˜è®¤
    return this.generateRawWithCustomAPI(options);
  }

  /**
   * ä½¿ç”¨æŒ‡å®šçš„APIé…ç½®è¿›è¡Œç”Ÿæˆ
   * é€‚ç”¨äºå¤šAPIé…ç½®åœºæ™¯ï¼Œå¯ä»¥ä¸ºä¸åŒåŠŸèƒ½ä½¿ç”¨ä¸åŒçš„API
   */
  async generateWithAPIConfig(
    options: GenerateOptions,
    apiConfig: {
      provider: APIProvider;
      url: string;
      apiKey: string;
      model: string;
      temperature?: number;
      maxTokens?: number;
    }
  ): Promise<string> {
    console.log(`[AIæœåŠ¡] ä½¿ç”¨æŒ‡å®šAPIé…ç½®ç”Ÿæˆï¼Œprovider: ${apiConfig.provider}, model: ${apiConfig.model}`);

    // ä¸´æ—¶ä¿å­˜å½“å‰é…ç½®ï¼ˆæ·±æ‹·è´ä»¥é¿å…å¼•ç”¨é—®é¢˜ï¼‰
    const originalConfig = this.config.customAPI ? { ...this.config.customAPI } : null;

    try {
      // ä½¿ç”¨æŒ‡å®šçš„APIé…ç½®
      this.config.customAPI = {
        provider: apiConfig.provider,
        url: apiConfig.url,
        apiKey: apiConfig.apiKey,
        model: apiConfig.model,
        temperature: apiConfig.temperature ?? 0.7,
        maxTokens: apiConfig.maxTokens ?? 16000
      };

      // å¼ºåˆ¶ä½¿ç”¨customæ¨¡å¼
      const result = await this.generateWithCustomAPI(options);

      return result;
    } finally {
      // æ¢å¤åŸé…ç½®
      if (originalConfig) {
        this.config.customAPI = originalConfig;
      }
    }
  }

  /**
   * ä½¿ç”¨æŒ‡å®šçš„APIé…ç½®è¿›è¡Œçº¯å‡€ç”Ÿæˆï¼ˆä¸å¸¦è§’è‰²å¡ï¼‰
   */
  async generateRawWithAPIConfig(
    options: GenerateOptions,
    apiConfig: {
      provider: APIProvider;
      url: string;
      apiKey: string;
      model: string;
      temperature?: number;
      maxTokens?: number;
    }
  ): Promise<string> {
    console.log(`[AIæœåŠ¡] ä½¿ç”¨æŒ‡å®šAPIé…ç½®è¿›è¡Œçº¯å‡€ç”Ÿæˆï¼Œprovider: ${apiConfig.provider}, model: ${apiConfig.model}`);

    // ä¸´æ—¶ä¿å­˜å½“å‰é…ç½®ï¼ˆæ·±æ‹·è´ä»¥é¿å…å¼•ç”¨é—®é¢˜ï¼‰
    const originalConfig = this.config.customAPI ? { ...this.config.customAPI } : null;

    try {
      // ä½¿ç”¨æŒ‡å®šçš„APIé…ç½®
      this.config.customAPI = {
        provider: apiConfig.provider,
        url: apiConfig.url,
        apiKey: apiConfig.apiKey,
        model: apiConfig.model,
        temperature: apiConfig.temperature ?? 0.7,
        maxTokens: apiConfig.maxTokens ?? 16000
      };

      // å¼ºåˆ¶ä½¿ç”¨customæ¨¡å¼
      const result = await this.generateRawWithCustomAPI(options);

      return result;
    } finally {
      // æ¢å¤åŸé…ç½®
      if (originalConfig) {
        this.config.customAPI = originalConfig;
      }
    }
  }

  // ============ é…’é¦†æ¨¡å¼å®ç° ============
  private async generateWithTavern(options: GenerateOptions): Promise<string> {
    const tavernHelper = this.getTavernHelper();
    if (!tavernHelper) {
      throw new Error(this.isTavernEnvironment()
        ? 'é…’é¦†ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼æˆ–åœ¨SillyTavernä¸­æ‰“å¼€'
        : 'å½“å‰ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼');
    }

    console.log('[AIæœåŠ¡-é…’é¦†] è°ƒç”¨tavernHelper.generate');
    try {
      return await this.withRetry('tavern.generate', () => tavernHelper.generate(options));
    } catch (error) {
      throw this.toUserFacingError(error);
    }
  }

  private async generateRawWithTavern(options: GenerateOptions): Promise<string> {
    const tavernHelper = this.getTavernHelper();
    if (!tavernHelper) {
      throw new Error(this.isTavernEnvironment()
        ? 'é…’é¦†ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼æˆ–åœ¨SillyTavernä¸­æ‰“å¼€'
        : 'å½“å‰ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼');
    }

    console.log('[AIæœåŠ¡-é…’é¦†] è°ƒç”¨tavernHelper.generateRaw');
    try {
      const result = await this.withRetry('tavern.generateRaw', () => tavernHelper.generateRaw(options));
      return String(result);
    } catch (error) {
      throw this.toUserFacingError(error);
    }
  }

  private async withRetry<T>(
    label: string,
    fn: () => Promise<T>,
    opts?: { retries?: number; baseDelayMs?: number },
  ): Promise<T> {
    const retries = opts?.retries ?? 2; // æ€»å°è¯•æ¬¡æ•° = 1 + retries
    const baseDelayMs = opts?.baseDelayMs ?? 800;

    let lastError: unknown;
    for (let attempt = 0; attempt <= retries; attempt++) {
      // æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
      if (this.isAborted) {
        console.log(`[AIæœåŠ¡] ${label} è¯·æ±‚å·²è¢«å–æ¶ˆï¼Œåœæ­¢é‡è¯•`);
        throw new Error('è¯·æ±‚å·²å–æ¶ˆ');
      }

      try {
        return await fn();
      } catch (error) {
        // å†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
        if (this.isAborted) {
          console.log(`[AIæœåŠ¡] ${label} è¯·æ±‚å·²è¢«å–æ¶ˆï¼Œåœæ­¢é‡è¯•`);
          throw new Error('è¯·æ±‚å·²å–æ¶ˆ');
        }

        lastError = error;
        const retryable = this.isRetryableError(error);
        if (!retryable || attempt >= retries) break;

        const jitter = Math.floor(Math.random() * 250);
        const delay = baseDelayMs * Math.pow(2, attempt) + jitter;
        console.warn(`[AIæœåŠ¡] ${label} å¤±è´¥ï¼Œå‡†å¤‡é‡è¯• (${attempt + 1}/${retries + 1})ï¼Œ${delay}ms`, error);

        // ä½¿ç”¨å¯ä¸­æ–­çš„å»¶è¿Ÿ
        await new Promise((resolve, reject) => {
          const timer = setTimeout(resolve, delay);
          // å¦‚æœåœ¨ç­‰å¾…æœŸé—´è¢«å–æ¶ˆï¼Œç«‹å³ç»“æŸ
          const checkAbort = setInterval(() => {
            if (this.isAborted) {
              clearTimeout(timer);
              clearInterval(checkAbort);
              reject(new Error('è¯·æ±‚å·²å–æ¶ˆ'));
            }
          }, 100);
          // æ­£å¸¸å®Œæˆæ—¶æ¸…ç†æ£€æŸ¥å™¨
          setTimeout(() => clearInterval(checkAbort), delay + 10);
        });
      }
    }
    throw lastError;
  }

  private isRetryableError(error: unknown): boolean {
    const message = (() => {
      if (!error) return '';
      if (typeof error === 'string') return error;
      if (error instanceof Error) return error.message || '';
      return String(error);
    })();

    // axios / fetch-like errors
    const status = (() => {
      const anyErr = error as any;
      return anyErr?.status ?? anyErr?.response?.status ?? anyErr?.cause?.status ?? anyErr?.cause?.response?.status;
    })();

    if (typeof status === 'number') {
      return [408, 409, 425, 429, 500, 502, 503, 504].includes(status);
    }

    // SillyTavern/OpenAI proxy errors oftenåªæœ‰ message
    if (/service unavailable/i.test(message)) return true;
    if (/\b(429|500|502|503|504)\b/.test(message)) return true;
    if (/timeout|timed out|network error|fetch failed/i.test(message)) return true;

    return false;
  }

  private toUserFacingError(error: unknown): Error {
    const anyErr = error as any;
    const message = (() => {
      if (!error) return 'æœªçŸ¥é”™è¯¯';
      if (typeof error === 'string') return error;
      if (error instanceof Error) return error.message || 'æœªçŸ¥é”™è¯¯';
      return String(error);
    })();

    const status = anyErr?.status ?? anyErr?.response?.status ?? anyErr?.cause?.status ?? anyErr?.cause?.response?.status;

    // é‡ç‚¹æç¤ºï¼š503/æœåŠ¡ä¸å¯ç”¨ï¼ˆç”¨æˆ·æ—¥å¿—é‡Œå°±æ˜¯è¿™ä¸ªï¼‰
    if (status === 503 || /service unavailable/i.test(message)) {
      const e = new Error(
        'AI æœåŠ¡æš‚ä¸å¯ç”¨ï¼ˆService Unavailable/503ï¼‰ã€‚æˆ‘å·²è‡ªåŠ¨é‡è¯•ä»å¤±è´¥ï¼šå¦‚æœåœ¨ SillyTavern å†…ä½¿ç”¨ï¼Œè¯·æ£€æŸ¥å½“å‰ API æä¾›æ–¹/ä»£ç†/é¢åº¦æ˜¯å¦æ­£å¸¸ï¼›ä¹Ÿå¯èƒ½æ˜¯ä¸Šæ¸¸ä¸´æ—¶æ•…éšœï¼Œç¨åå†è¯•ã€‚'
      );
      (e as any).cause = error;
      return e;
    }

    if (status === 429 || /\b429\b/.test(message)) {
      const e = new Error('AI è¯·æ±‚è¿‡äºé¢‘ç¹ï¼ˆ429ï¼‰ã€‚æˆ‘å·²è‡ªåŠ¨é‡è¯•ï¼Œä»å¤±è´¥è¯·ç¨åå†è¯•æˆ–é™ä½å¹¶å‘/é¢‘ç‡ã€‚');
      (e as any).cause = error;
      return e;
    }

    // ä¿ç•™åŸå§‹ä¿¡æ¯ï¼Œä½†é¿å…ç›´æ¥æŠŠå¯¹è±¡æ‰“å°åˆ° toast é‡Œ
    const e = new Error(message || 'AI è°ƒç”¨å¤±è´¥');
    (e as any).cause = error;
    return e;
  }

  /**
   * é€’å½’å‘ä¸ŠæŸ¥æ‰¾ TavernHelperï¼Œå…¼å®¹å¤šå±‚ iframe åµŒå¥—
   * æœ€å¤šæŸ¥æ‰¾ 5 å±‚ï¼Œé˜²æ­¢æ— é™å¾ªç¯
   */
  private getTavernHelper(): any {
    if (typeof window === 'undefined') return null;

    // å…ˆæ£€æŸ¥å½“å‰ window
    if ((window as any).TavernHelper) {
      return (window as any).TavernHelper;
    }

    try {
      // å°è¯•ç›´æ¥è®¿é—® topï¼ˆæœ€é¡¶å±‚çª—å£ï¼‰
      if (window.top && window.top !== window && (window.top as any).TavernHelper) {
        return (window.top as any).TavernHelper;
      }
    } catch {
      // è·¨åŸŸè®¿é—®å¤±è´¥ï¼Œå¿½ç•¥
    }

    // é€å±‚å‘ä¸ŠæŸ¥æ‰¾ï¼Œæœ€å¤š 5 å±‚
    let currentWindow: Window = window;
    for (let i = 0; i < 5; i++) {
      try {
        if (currentWindow.parent && currentWindow.parent !== currentWindow) {
          if ((currentWindow.parent as any).TavernHelper) {
            return (currentWindow.parent as any).TavernHelper;
          }
          currentWindow = currentWindow.parent;
        } else {
          break;
        }
      } catch {
        // è·¨åŸŸè®¿é—®å¤±è´¥ï¼Œåœæ­¢å‘ä¸ŠæŸ¥æ‰¾
        break;
      }
    }

    return null;
  }

  private isTavernEnvironment(): boolean {
    return !!this.getTavernHelper();
  }

  // ============ è‡ªå®šä¹‰APIæ¨¡å¼å®ç° ============
  private async generateWithCustomAPI(options: GenerateOptions): Promise<string> {
    if (!this.config.customAPI) {
      throw new Error('è‡ªå®šä¹‰APIæœªé…ç½®');
    }

    console.log('[AIæœåŠ¡-è‡ªå®šä¹‰] æ„å»ºæ¶ˆæ¯åˆ—è¡¨');

    // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    const messages: AIMessage[] = [];

    // å¤„ç† injectsï¼ˆæ³¨å…¥çš„ç³»ç»Ÿæç¤ºè¯ï¼‰
    if (options.injects && options.injects.length > 0) {
      // æŒ‰ depth æ’åºï¼ˆdepthè¶Šå¤§è¶Šé å‰ï¼‰
      const sortedInjects = [...options.injects].sort((a, b) => b.depth - a.depth);
      sortedInjects.forEach(inject => {
        // è·³è¿‡å ä½æ¶ˆæ¯
        if (inject.content === '</input>') {
          return;
        }
        messages.push({
          role: inject.role,
          content: inject.content
        });
      });
      console.log(`[AIæœåŠ¡-è‡ªå®šä¹‰] å·²æ·»åŠ  ${messages.length} æ¡injectæ¶ˆæ¯`);
    }

    // æ·»åŠ ç”¨æˆ·è¾“å…¥
    if (options.user_input) {
      messages.push({
        role: 'user',
        content: options.user_input
      });
      console.log('[AIæœåŠ¡-è‡ªå®šä¹‰] å·²æ·»åŠ ç”¨æˆ·è¾“å…¥');
    }

    const shouldStream = options.should_stream ?? this.config.streaming ?? false;
    return this.callAPI(messages, shouldStream, options.onStreamChunk);
  }

  private async generateRawWithCustomAPI(options: GenerateOptions): Promise<string> {
    if (!this.config.customAPI) {
      throw new Error('è‡ªå®šä¹‰APIæœªé…ç½®');
    }

    console.log('[AIæœåŠ¡-è‡ªå®šä¹‰Raw] ä½¿ç”¨ordered_prompts');

    // è¿‡æ»¤æ‰å ä½æ¶ˆæ¯
    const messages = (options.ordered_prompts || []).filter(msg => msg.content !== '</input>');

    console.log(`[AIæœåŠ¡-è‡ªå®šä¹‰Raw] æ¶ˆæ¯æ•°é‡: ${messages.length}`);
    const shouldStream = options.should_stream ?? this.config.streaming ?? false;
    return this.callAPI(messages, shouldStream, options.onStreamChunk);
  }

  private async callAPI(
    messages: AIMessage[],
    streaming: boolean,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    const { provider, url, apiKey, model, temperature, maxTokens } = this.config.customAPI!;

    console.log(`[AIæœåŠ¡-APIè°ƒç”¨] Provider: ${provider}, URL: ${url}, Model: ${model}, æ¶ˆæ¯æ•°: ${messages.length}, æµå¼: ${streaming}`);

    // æ ¹æ®provideré€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
    switch (provider) {
      case 'claude':
        return this.callClaudeAPI(messages, streaming, onStreamChunk);
      case 'gemini':
        return this.callGeminiAPI(messages, streaming, onStreamChunk);
      case 'openai':
      case 'deepseek':
      case 'custom':
      default:
        return this.callOpenAICompatibleAPI(messages, streaming, onStreamChunk);
    }
  }

  // OpenAIå…¼å®¹æ ¼å¼ï¼ˆOpenAIã€DeepSeekã€è‡ªå®šä¹‰ï¼‰
  private estimateTokensForText(text: string): number {
    if (!text) return 0;
    let cjkCount = 0;
    for (const ch of text) {
      const code = ch.charCodeAt(0);
      if (code >= 0x4e00 && code <= 0x9fff) cjkCount++;
    }
    const nonCjkCount = Math.max(0, text.length - cjkCount);
    return cjkCount + Math.ceil(nonCjkCount / 4);
  }

  private estimateTokensForMessages(messages: Array<{ content: string }>): number {
    const overheadPerMessage = 8;
    return messages.reduce((sum, msg) => sum + overheadPerMessage + this.estimateTokensForText(msg.content || ''), 0);
  }

  private getApproxContextWindow(provider: APIProvider, model: string): number | null {
    const m = (model || '').toLowerCase();

    // Provider/model with known large context windows
    if (provider === 'claude' || m.includes('claude')) return 200_000;
    if (provider === 'gemini' || m.includes('gemini')) return 1_000_000;

    // Many OpenAI-compatible providers expose these model names; match by model string first.
    if (m.includes('deepseek')) return 64_000;
    if (m.includes('moonshot') || m.includes('kimi')) return 128_000;

    // OpenAI-compatible defaults
    if (m.includes('gpt-4o') || m.includes('gpt-4.1') || m.includes('o1') || m.includes('o3')) return 128_000;
    if (m.includes('gpt-4')) return 128_000;
    if (m.includes('gpt-3.5')) return 16_385;

    // Unknown model: don't guess (this project often uses 10k+ token prompts).
    return null;
  }

  private clampMaxTokensForContext(
    provider: APIProvider,
    model: string,
    messagesForEstimate: Array<{ content: string }>,
    requestedMaxTokens: number
  ): number {
    const contextWindow = this.getApproxContextWindow(provider, model);
    if (!contextWindow) return requestedMaxTokens;

    const inputTokens = this.estimateTokensForMessages(messagesForEstimate);
    const safety = 512;
    const available = contextWindow - inputTokens - safety;

    if (available < 256) {
      throw new Error(`APIä¸Šä¸‹æ–‡é•¿åº¦ä¸è¶³ï¼šè¾“å…¥è¿‡é•¿ï¼ˆä¼°ç®—è¾“å…¥â‰ˆ${inputTokens} tokensï¼‰ï¼Œè¯·å‡å°‘ä¸–ç•Œ/æç¤ºè¯é•¿åº¦æˆ–æ›´æ¢æ›´å¤§ä¸Šä¸‹æ–‡æ¨¡å‹ã€‚`);
    }

    const clamped = Math.min(requestedMaxTokens, Math.max(256, available));
    if (clamped < requestedMaxTokens) {
      console.warn(`[AIæœåŠ¡] maxTokensè¿‡å¤§ï¼Œå·²è‡ªåŠ¨ä¸‹è°ƒï¼š${requestedMaxTokens} -> ${clamped}ï¼ˆä¼°ç®—è¾“å…¥â‰ˆ${inputTokens}ï¼Œæ¨¡å‹ä¸Šä¸‹æ–‡â‰ˆ${contextWindow}ï¼‰`);
    }
    return clamped;
  }

  private isStreamUnsupportedError(message: string): boolean {
    const m = (message || '').toLowerCase();
    return (
      (m.includes('stream') && (m.includes('not supported') || m.includes('unsupported') || m.includes('invalid') || m.includes('unknown'))) ||
      m.includes('text/event-stream') ||
      m.includes('sse')
    );
  }

  private async callOpenAICompatibleAPI(
    messages: AIMessage[],
    streaming: boolean,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    const { provider, url, apiKey, model, temperature, maxTokens } = this.config.customAPI!;
    const safeMaxTokens = this.clampMaxTokensForContext(provider, model, messages, maxTokens || 16000);

    try {
      if (streaming) {
        try {
          return await this.streamingRequestOpenAI(url, apiKey, model, messages, temperature || 0.7, safeMaxTokens, onStreamChunk);
        } catch (e) {
          const msg = e instanceof Error ? e.message : String(e);
          if (!this.isStreamUnsupportedError(msg)) throw e;
          console.warn('[AIæœåŠ¡-OpenAIå…¼å®¹] å½“å‰APIå¯èƒ½ä¸æ”¯æŒæµå¼ä¼ è¾“ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºéæµå¼è¯·æ±‚ã€‚');

          const response = await axios.post(
            `${url}/v1/chat/completions`,
            {
              model,
              messages,
              temperature: temperature || 0.7,
              max_tokens: safeMaxTokens,
              stream: false
            },
            {
              headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
              },
              timeout: 120000
            }
          );

          const content = response.data.choices[0].message.content;
          console.log(`[AIÃ¦Å“ÂÃ¥Å Â¡-OpenAI] Ã¥â€œÂÃ¥Âºâ€Ã©â€¢Â¿Ã¥ÂºÂ¦: ${content.length}`);
          return content;
        }
      } else {
        const response = await axios.post(
          `${url}/v1/chat/completions`,
          {
            model,
            messages,
            temperature: temperature || 0.7,
            max_tokens: safeMaxTokens,
            stream: false
          },
          {
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json'
            },
            timeout: 120000
          }
        );

        const content = response.data.choices[0].message.content;
        console.log(`[AIæœåŠ¡-OpenAI] å“åº”é•¿åº¦: ${content.length}`);
        return content;
      }
    } catch (error) {
      console.error('[AIæœåŠ¡-OpenAI] å¤±è´¥:', error);
      if (axios.isAxiosError(error)) {
        if (error.response) {
          throw new Error(`APIé”™è¯¯ ${error.response.status}: ${JSON.stringify(error.response.data)}`);
        } else if (error.request) {
          throw new Error('ç½‘ç»œé”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨');
        }
      }
      throw new Error(`OpenAI APIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  // Claude APIæ ¼å¼
  private async callClaudeAPI(
    messages: AIMessage[],
    streaming: boolean,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    const { provider, url, apiKey, model, temperature, maxTokens } = this.config.customAPI!;

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼šæå–systemæ¶ˆæ¯ï¼Œå…¶ä½™è½¬ä¸ºClaudeæ ¼å¼
    let systemPrompt = '';
    const claudeMessages: Array<{ role: 'user' | 'assistant'; content: string }> = [];

    for (const msg of messages) {
      if (msg.role === 'system') {
        systemPrompt += (systemPrompt ? '\n\n' : '') + msg.content;
      } else {
        claudeMessages.push({ role: msg.role as 'user' | 'assistant', content: msg.content });
      }
    }

    // ç¡®ä¿ç¬¬ä¸€æ¡æ˜¯useræ¶ˆæ¯ï¼ˆClaudeè¦æ±‚ï¼‰
    if (claudeMessages.length === 0 || claudeMessages[0].role !== 'user') {
      claudeMessages.unshift({ role: 'user', content: 'è¯·å¼€å§‹ã€‚' });
    }

    const baseUrl = url || 'https://api.anthropic.com';
    const safeMaxTokens = this.clampMaxTokensForContext(
      provider,
      model,
      [
        ...(systemPrompt ? [{ content: systemPrompt }] : []),
        ...claudeMessages.map(m => ({ content: m.content })),
      ],
      maxTokens || 16000
    );

    try {
      if (streaming) {
        try {
          return await this.streamingRequestClaude(baseUrl, apiKey, model, systemPrompt, claudeMessages, temperature || 0.7, safeMaxTokens, onStreamChunk);
        } catch (e) {
          const msg = e instanceof Error ? e.message : String(e);
          if (!this.isStreamUnsupportedError(msg)) throw e;
          console.warn('[AIæœåŠ¡-Claude] å½“å‰APIå¯èƒ½ä¸æ”¯æŒæµå¼ä¼ è¾“ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºéæµå¼è¯·æ±‚ã€‚');

          const response = await axios.post(
            `${baseUrl}/v1/messages`,
            {
              model,
              max_tokens: safeMaxTokens,
              system: systemPrompt || undefined,
              messages: claudeMessages,
              temperature: temperature || 0.7
            },
            {
              headers: {
                'x-api-key': apiKey,
                'anthropic-version': '2023-06-01',
                'Content-Type': 'application/json'
              },
              timeout: 120000
            }
          );

          const content = response.data.content[0]?.text || '';
          console.log(`[AIæœåŠ¡-Claude] å“åº”é•¿åº¦: ${content.length}`);
          return content;
        }
      } else {
        const response = await axios.post(
          `${baseUrl}/v1/messages`,
          {
            model,
            max_tokens: safeMaxTokens,
            system: systemPrompt || undefined,
            messages: claudeMessages,
            temperature: temperature || 0.7
          },
          {
            headers: {
              'x-api-key': apiKey,
              'anthropic-version': '2023-06-01',
              'Content-Type': 'application/json'
            },
            timeout: 120000
          }
        );

        const content = response.data.content[0]?.text || '';
        console.log(`[AIæœåŠ¡-Claude] å“åº”é•¿åº¦: ${content.length}`);
        return content;
      }
    } catch (error) {
      console.error('[AIæœåŠ¡-Claude] å¤±è´¥:', error);
      if (axios.isAxiosError(error)) {
        if (error.response) {
          throw new Error(`Claude APIé”™è¯¯ ${error.response.status}: ${JSON.stringify(error.response.data)}`);
        }
      }
      throw new Error(`Claude APIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  // Gemini APIæ ¼å¼
  private async callGeminiAPI(
    messages: AIMessage[],
    streaming: boolean,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    const { provider, url, apiKey, model, temperature, maxTokens } = this.config.customAPI!;

    // è½¬æ¢ä¸ºGeminiæ ¼å¼
    let systemInstruction = '';
    const contents: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }> = [];

    for (const msg of messages) {
      if (msg.role === 'system') {
        systemInstruction += (systemInstruction ? '\n\n' : '') + msg.content;
      } else {
        contents.push({
          role: msg.role === 'assistant' ? 'model' : 'user',
          parts: [{ text: msg.content }]
        });
      }
    }

    // ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡æ¶ˆæ¯
    if (contents.length === 0) {
      contents.push({ role: 'user', parts: [{ text: 'è¯·å¼€å§‹ã€‚' }] });
    }

    const baseUrl = url || 'https://generativelanguage.googleapis.com';
    const endpoint = streaming ? 'streamGenerateContent' : 'generateContent';
    const safeMaxTokens = this.clampMaxTokensForContext(
      provider,
      model,
      [
        ...(systemInstruction ? [{ content: systemInstruction }] : []),
        ...contents.map(c => ({ content: (c.parts || []).map(p => p.text).join('\n') })),
      ],
      maxTokens || 16000
    );

    try {
      if (streaming) {
        try {
          return await this.streamingRequestGemini(baseUrl, apiKey, model, systemInstruction, contents, temperature || 0.7, safeMaxTokens, onStreamChunk);
        } catch (e) {
          const msg = e instanceof Error ? e.message : String(e);
          if (!this.isStreamUnsupportedError(msg)) throw e;
          console.warn('[AIæœåŠ¡-Gemini] å½“å‰APIå¯èƒ½ä¸æ”¯æŒæµå¼ä¼ è¾“ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºéæµå¼è¯·æ±‚ã€‚');

          const response = await axios.post(
            `${baseUrl}/v1beta/models/${model}:generateContent?key=${apiKey}`,
            {
              contents,
              systemInstruction: systemInstruction ? { parts: [{ text: systemInstruction }] } : undefined,
              generationConfig: {
                temperature: temperature || 0.7,
                maxOutputTokens: safeMaxTokens
              }
            },
            {
              headers: { 'Content-Type': 'application/json' },
              timeout: 120000
            }
          );

          const content = response.data.candidates?.[0]?.content?.parts?.[0]?.text || '';
          console.log(`[AIæœåŠ¡-Gemini] å“åº”é•¿åº¦: ${content.length}`);
          return content;
        }
      } else {
        const response = await axios.post(
          `${baseUrl}/v1beta/models/${model}:${endpoint}?key=${apiKey}`,
          {
            contents,
            systemInstruction: systemInstruction ? { parts: [{ text: systemInstruction }] } : undefined,
            generationConfig: {
              temperature: temperature || 0.7,
              maxOutputTokens: safeMaxTokens
            }
          },
          {
            headers: { 'Content-Type': 'application/json' },
            timeout: 120000
          }
        );

        const content = response.data.candidates?.[0]?.content?.parts?.[0]?.text || '';
        console.log(`[AIæœåŠ¡-Gemini] å“åº”é•¿åº¦: ${content.length}`);
        return content;
      }
    } catch (error) {
      console.error('[AIæœåŠ¡-Gemini] å¤±è´¥:', error);
      if (axios.isAxiosError(error)) {
        if (error.response) {
          throw new Error(`Gemini APIé”™è¯¯ ${error.response.status}: ${JSON.stringify(error.response.data)}`);
        }
      }
      throw new Error(`Gemini APIè°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  // OpenAIæ ¼å¼æµå¼è¯·æ±‚
  private async streamingRequestOpenAI(
    url: string,
    apiKey: string,
    model: string,
    messages: AIMessage[],
    temperature: number,
    maxTokens: number,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    console.log('[AIæœåŠ¡-OpenAIæµå¼] å¼€å§‹');

    const response = await fetch(`${url}/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Accept': 'text/event-stream',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        messages,
        temperature,
        max_tokens: maxTokens,
        stream: true
      })
    });

    if (!response.ok) {
      throw new Error(`APIé”™è¯¯ ${response.status}: ${await response.text()}`);
    }

    const contentType = response.headers.get('content-type') || '';
    if (!contentType.includes('text/event-stream')) {
      throw new Error(`Stream unsupported (content-type=${contentType || 'unknown'})`);
    }

    return this.processSSEStream(response, (data) => {
      const parsed = JSON.parse(data);
      const delta = parsed.choices[0]?.delta;
      // ğŸ”¥ å…¼å®¹ Gemini/DeepSeek ç­‰æ¨¡å‹çš„ reasoning_content å­—æ®µ
      // è¿™äº›æ¨¡å‹ä¼šå…ˆè¾“å‡º reasoning_contentï¼ˆæ€ç»´é“¾ï¼‰ï¼Œç„¶åè¾“å‡º contentï¼ˆå®é™…å†…å®¹ï¼‰
      // reasoning_content ä¼šè¢«åŒ…è£¹åœ¨ <thinking> æ ‡ç­¾ä¸­ï¼Œç”± processSSEStream è¿‡æ»¤
      if (delta?.reasoning_content) {
        return `<thinking>${delta.reasoning_content}</thinking>`;
      }
      return delta?.content || '';
    }, onStreamChunk);
  }

  // Claudeæ ¼å¼æµå¼è¯·æ±‚
  private async streamingRequestClaude(
    url: string,
    apiKey: string,
    model: string,
    systemPrompt: string,
    messages: Array<{ role: 'user' | 'assistant'; content: string }>,
    temperature: number,
    maxTokens: number,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    console.log('[AIæœåŠ¡-Claudeæµå¼] å¼€å§‹');

    const response = await fetch(`${url}/v1/messages`, {
      method: 'POST',
      headers: {
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
        'Accept': 'text/event-stream',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        max_tokens: maxTokens,
        system: systemPrompt || undefined,
        messages,
        temperature,
        stream: true
      })
    });

    if (!response.ok) {
      throw new Error(`Claude APIé”™è¯¯ ${response.status}: ${await response.text()}`);
    }

    const contentType = response.headers.get('content-type') || '';
    if (!contentType.includes('text/event-stream')) {
      throw new Error(`Stream unsupported (content-type=${contentType || 'unknown'})`);
    }

    return this.processSSEStream(response, (data) => {
      const parsed = JSON.parse(data);
      // Claudeæµå¼å“åº”æ ¼å¼ï¼šcontent_block_deltaäº‹ä»¶
      if (parsed.type === 'content_block_delta') {
        return parsed.delta?.text || '';
      }
      return '';
    }, onStreamChunk);
  }

  // Geminiæ ¼å¼æµå¼è¯·æ±‚
  private async streamingRequestGemini(
    url: string,
    apiKey: string,
    model: string,
    systemInstruction: string,
    contents: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }>,
    temperature: number,
    maxTokens: number,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    console.log('[AIæœåŠ¡-Geminiæµå¼] å¼€å§‹');

    const response = await fetch(`${url}/v1beta/models/${model}:streamGenerateContent?key=${apiKey}&alt=sse`, {
      method: 'POST',
      headers: { 'Accept': 'text/event-stream', 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents,
        systemInstruction: systemInstruction ? { parts: [{ text: systemInstruction }] } : undefined,
        generationConfig: {
          temperature,
          maxOutputTokens: maxTokens
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Gemini APIé”™è¯¯ ${response.status}: ${await response.text()}`);
    }

    const contentType = response.headers.get('content-type') || '';
    if (!contentType.includes('text/event-stream')) {
      throw new Error(`Stream unsupported (content-type=${contentType || 'unknown'})`);
    }

    return this.processSSEStream(response, (data) => {
      const parsed = JSON.parse(data);
      return parsed.candidates?.[0]?.content?.parts?.[0]?.text || '';
    }, onStreamChunk);
  }

  // é€šç”¨SSEæµå¤„ç†ï¼ˆå¸¦thinkingæ ‡ç­¾è¿‡æ»¤ï¼‰
  private async processSSEStream(
    response: Response,
    extractContent: (data: string) => string,
    onStreamChunk?: (chunk: string) => void
  ): Promise<string> {
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('æ— æ³•è·å–å“åº”æµ');
    }

    const decoder = new TextDecoder();
    let rawFullText = '';
    let buffer = '';
    let inThinkingTag = false;
    let thinkingBuffer = '';
    const nowMs = () => (typeof performance !== 'undefined' && performance.now ? performance.now() : Date.now());
    const yieldToUi = () => new Promise<void>((resolve) => {
      if (typeof requestAnimationFrame === 'function') {
        requestAnimationFrame(() => resolve());
      } else {
        setTimeout(resolve, 0);
      }
    });
    let lastYieldAt = nowMs();
    let pendingChars = 0;
    const maybeYield = async (addedChars: number) => {
      if (!onStreamChunk) return;
      pendingChars += addedChars;
      const now = nowMs();
      if (pendingChars >= 80 || now - lastYieldAt >= 60) {
        pendingChars = 0;
        lastYieldAt = now;
        await yieldToUi();
      }
    };

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          const trimmed = line.trim();
          if (!trimmed || !trimmed.startsWith('data:')) continue;

          let data = trimmed.slice(5);
          if (data.startsWith(' ')) data = data.slice(1);
          if (data === '[DONE]') continue;

          try {
            const content = extractContent(data);
            if (content) {
              rawFullText += content;
              // å¤„ç†thinkingæ ‡ç­¾è¿‡æ»¤
              for (let i = 0; i < content.length; i++) {
                const char = content[i];
                thinkingBuffer += char;

                if (thinkingBuffer.includes('<thinking>')) {
                  inThinkingTag = true;
                  thinkingBuffer = '';
                  continue;
                }

                if (inThinkingTag && thinkingBuffer.includes('</thinking>')) {
                  inThinkingTag = false;
                  thinkingBuffer = '';
                  continue;
                }

                // å®¹é”™ï¼šéƒ¨åˆ†æ¨¡å‹å¯èƒ½ä¸ä¼šè¾“å‡º </thinking>ï¼Œä½†ä¼šç›´æ¥å¼€å§‹è¾“å‡º ```json
                // æ­¤æ—¶ä¸ºäº†é¿å…æŠŠåç»­JSONä¹Ÿåæ‰ï¼Œæ£€æµ‹åˆ°ä»£ç å—èµ·å§‹åè‡ªåŠ¨ç»“æŸ thinking è¿‡æ»¤ã€‚
                if (inThinkingTag) {
                  const jsonFenceIndex = thinkingBuffer.indexOf('```json');
                  const anyFenceIndex = thinkingBuffer.indexOf('```');
                  const fenceIndex = jsonFenceIndex !== -1 ? jsonFenceIndex : anyFenceIndex;

                  if (fenceIndex !== -1) {
                    const carry = thinkingBuffer.slice(fenceIndex);
                    inThinkingTag = false;
                    thinkingBuffer = '';
                    if (onStreamChunk) onStreamChunk(carry);
                    await maybeYield(carry.length);
                    continue;
                  }
                }

                if (!inThinkingTag) {
                  const possibleTagStart = '<thinking>'.startsWith(thinkingBuffer) ||
                                          '</thinking>'.startsWith(thinkingBuffer);

                    if (!possibleTagStart && thinkingBuffer.length > 0) {
                      if (onStreamChunk) {
                        console.log('[AIæœåŠ¡-æµå¼] å‘é€chunkåˆ°å‰ç«¯:', thinkingBuffer.length, 'å­—ç¬¦');
                        onStreamChunk(thinkingBuffer);
                      }
                      await maybeYield(thinkingBuffer.length);
                      thinkingBuffer = '';
                    } else if (thinkingBuffer.length > 10) {
                      if (onStreamChunk) {
                        console.log('[AIæœåŠ¡-æµå¼] å‘é€chunkåˆ°å‰ç«¯(ç¼“å†²åŒºè¿‡å¤§):', thinkingBuffer.length, 'å­—ç¬¦');
                        onStreamChunk(thinkingBuffer);
                      }
                      await maybeYield(thinkingBuffer.length);
                      thinkingBuffer = '';
                    }
                  }
                }
            }
          } catch (e) {
            console.warn('[AIæœåŠ¡-æµå¼] è§£æchunkå¤±è´¥:', data.substring(0, 100));
          }
        }
      }

      if (!inThinkingTag && thinkingBuffer.length > 0) {
        if (onStreamChunk) onStreamChunk(thinkingBuffer);
        await maybeYield(thinkingBuffer.length);
      }
    } finally {
      reader.releaseLock();
    }

    console.log(`[AIæœåŠ¡-æµå¼] å®Œæˆï¼Œæ€»é•¿åº¦: ${rawFullText.length}`);
    return rawFullText;
  }

  /**
   * æ£€æŸ¥å½“å‰æ¨¡å¼æ˜¯å¦å¯ç”¨
   */
  checkAvailability(): { available: boolean; message: string } {
    if (this.config.mode === 'tavern') {
      const tavernHelper = this.getTavernHelper();
      if (!tavernHelper) {
        return {
          available: false,
          message: this.isTavernEnvironment()
            ? 'é…’é¦†ç¯å¢ƒä¸å¯ç”¨ã€‚è¯·åœ¨SillyTavernä¸­æ‰“å¼€ï¼Œæˆ–åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼ã€‚'
            : 'å½“å‰ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°è‡ªå®šä¹‰APIæ¨¡å¼ã€‚'
        };
      }
      return { available: true, message: 'é…’é¦†æ¨¡å¼å·²å°±ç»ª' };
    } else {
      if (!this.config.customAPI?.url || !this.config.customAPI?.apiKey) {
        return {
          available: false,
          message: 'è‡ªå®šä¹‰APIæœªé…ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­é…ç½®APIåœ°å€å’Œå¯†é’¥ã€‚'
        };
      }
      return { available: true, message: 'è‡ªå®šä¹‰APIæ¨¡å¼å·²å°±ç»ª' };
    }
  }
}

export const aiService = new AIService();
